{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enviroment: flappy bird\n",
    "    # 4 states (normalized), 2 actions\n",
    "    #  reward: -5 die, +0.05 survive, +5 pass pipe\n",
    "\n",
    "# framework: tf.keras\n",
    "# model: RL A2C (2 NN)\n",
    "    # method: Advantage = Q - value where Q = R + discount * Q'\n",
    "    # Actor: 4 input | 64 relu | 64 relu | softmax -> policy. loss: mean (log policy * advantage)\n",
    "    # Critic: 4 input | 64 relu | 64 relu | linear -> value. loss: mean square (advantage)\n",
    "    # hyperparams: discount 0.999, optimizer adam-learning rate 0.001\n",
    "\n",
    "# result: 1.5 points mva at ep1000\n",
    "    # can't make it pass 2.0 mva after ep5000, peaked 17 by luck (maybe met local minimum loss)\n",
    "\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pygame\n",
    "import sys\n",
    "from enviroment import FlappyBird\n",
    "from modelA2C import A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = FlappyBird()\n",
    "scores, rewards = [], []\n",
    "\n",
    "model = A2C(0.999)\n",
    "model.actor = tf.keras.models.load_model('models/A2Cactor.keras')\n",
    "model.critic = tf.keras.models.load_model('models/A2Ccritic.keras')\n",
    "\n",
    "for episode in range(10000):\n",
    "    model.training_loop(env, 10000)\n",
    "    scores.append(model.score)\n",
    "    rewards.append(model.reward)\n",
    "    display.clear_output(wait=True)\n",
    "    print(f\"Episode {episode}:\")\n",
    "    print(f\"current score: {model.score:.2f}, highest score: {max(scores):.2f}, avg score: {np.mean(scores):.2f}\")\n",
    "    print(f\"current reward: {model.reward:.2f}, highest reward: {max(rewards):.2f}, avg reward: {np.mean(rewards):.2f}\")\n",
    "pygame.quit()\n",
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reward EMA\n",
    "previous_reward = 0\n",
    "R_EMA = []\n",
    "factor = 2 / (1+50)\n",
    "for reward in rewards:\n",
    "    if previous_reward != 0:\n",
    "        new_reward = previous_reward * (1 - factor) + reward * factor\n",
    "    else:\n",
    "        new_reward = reward\n",
    "    previous_reward = new_reward\n",
    "    \n",
    "    R_EMA.append(new_reward)\n",
    "\n",
    "plt.plot(list(range(len(rewards))), rewards, alpha=0.5, label=\"Reward\")\n",
    "plt.plot(list(range(len(R_EMA))), R_EMA, label=\"Exponential Moving Average\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score EMA\n",
    "previous_score = 0\n",
    "S_EMA = []\n",
    "factor = 2 / (1+50)\n",
    "for score in scores:\n",
    "    if previous_score != 0:\n",
    "        new_score = previous_score * (1 - factor) + score * factor\n",
    "    else:\n",
    "        new_score = score\n",
    "    previous_score = new_score\n",
    "    \n",
    "    S_EMA.append(new_score)\n",
    "\n",
    "plt.plot(list(range(len(scores))), scores, alpha=0.5, label=\"Score\")\n",
    "plt.plot(list(range(len(S_EMA))), S_EMA, label=\"Exponential Moving Average\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.actor.save('A2Cactor.keras')\n",
    "model.critic.save('A2Ccritic.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
