{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enviroment: flappy bird\n",
    "    # 4 states (normalized), 2 actions\n",
    "    #  reward: -5 die, +0.05 survive, +5 pass pipe\n",
    "\n",
    "# framework: tf.keras\n",
    "# model: RL PPO (2 NN)\n",
    "    # method: Advantage = Q - value where Q = R + discount * Q'\n",
    "    # Actor: 4 input | 64 relu | 64 relu | softmax -> policy. loss: mean (log policy * advantage)\n",
    "    # Critic: 4 input | 64 relu | 64 relu | linear -> value. loss: mean square (advantage)\n",
    "    # params: discount 0.999, optimizer adam-learning rate 0.001, no e-greedy\n",
    "\n",
    "# result:\n",
    "\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from enviroment import FlappyBird\n",
    "from modelPPO import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
